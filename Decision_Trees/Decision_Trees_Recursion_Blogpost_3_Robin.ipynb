{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please read the blog post, and codealong in this Jupyter notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/decision-tree-from-scratch-in-python-46e99dfea775\n",
    "\n",
    "Please refer to \"Recursion\" from https://cr.yp.to/2005-261/bender2/DT.pdf , https://medium.com/greyatom/decision-trees-a-simple-way-to-visualize-a-decision-dc506a403aeb, https://www.ke.tu-darmstadt.de/lehre/archiv/ws0809/mldm/dt.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://towardsdatascience.com/decision-tree-from-scratch-in-python-46e99dfea775"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier():\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Build the decision tree classifier.\n",
    "        '''\n",
    "        self.n_classes_ = len(set(y))\n",
    "        self.n_features_ = X.shape[1]\n",
    "        self.tree_ = self._grow_tree(X, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return [self._predict(inputs) for inputs in X]\n",
    "        \n",
    "    def _predict(self, inputs):\n",
    "        '''\n",
    "        Predict class for single sample\n",
    "        '''\n",
    "        node = self.tree_\n",
    "        while node.left:\n",
    "            if inputs[node.feature_index] < node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.predicted_class\n",
    "    \n",
    "    def _gini(self, y):\n",
    "        \"\"\"Compute Gini impurity of a non-empty node.\n",
    "        Gini impurity is defined as Σ p(1-p) over all classes, with p the frequency of a\n",
    "        class within the node. Since Σ p = 1, this is equivalent to 1 - Σ p^2.\n",
    "        \"\"\"\n",
    "        m = y.size\n",
    "        return 1.0 - sum((np.sum(y == c) / m) ** 2 for c in range(self.n_classes_))\n",
    "        \n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        '''\n",
    "        Build a decision tree by recursively finding the best split.\n",
    "        '''\n",
    "        # Population for each class in current node. \n",
    "        # The predicted class is the one with\n",
    "        # largest population.\n",
    "        num_samples_per_class = [np.sum(y == i) for i in range(self.n_classes_)]\n",
    "        print(num_samples_per_class)\n",
    "        predicted_class = np.argmax(num_samples_per_class)\n",
    "        print(predicted_class)\n",
    "        \n",
    "        node = Node(\n",
    "            gini=self._gini(y),\n",
    "            num_samples=y.shape,\n",
    "            num_samples_per_class=num_samples_per_class,\n",
    "            predicted_class=predicted_class,\n",
    "        )\n",
    "        \n",
    "        # Split recursively until max_depth is reached\n",
    "        if depth < self.max_depth:\n",
    "            idx, thr = self._best_split(X, y)\n",
    "            if idx is not None:\n",
    "                indices_left = X[:, idx] < thr\n",
    "                X_left, y_left = X[indices_left], y[indices_left]\n",
    "                # using ~ will start counting index from the right instead of left\n",
    "                X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "                node.feature_index = idx\n",
    "                node.threshold = thr\n",
    "                node.left = self._grow_tree(X_left, y_left, depth + 1)\n",
    "                node.right = self._grow_tree(X_right, y_right, depth + 1)\n",
    "        return node\n",
    "        \n",
    "        \n",
    "    def _best_split(self, X, y):\n",
    "        \"\"\"Find the best split for a node.\n",
    "        \"Best\" means that the average impurity of the two children, weighted by their\n",
    "        population, is the smallest possible. Additionally it must be less than the\n",
    "        impurity of the current node.\n",
    "        To find the best split, we loop through all the features, and consider all the\n",
    "        midpoints between adjacent training samples as possible thresholds. We compute\n",
    "        the Gini impurity of the split generated by that particular feature/threshold\n",
    "        pair, and return the pair with smallest impurity.\n",
    "        Returns:\n",
    "            best_idx: Index of the feature for best split, or None if no split is found.\n",
    "            best_thr: Threshold to use for the split, or None if no split is found.\n",
    "        \"\"\"\n",
    "        \n",
    "        m = y.size\n",
    "        if m <= 1:\n",
    "            return None, None\n",
    "        \n",
    "        num_parent = [np.sum(y == c) for c in range(self.n_classes_)]\n",
    "        \n",
    "        # Calculates Gini of current node\n",
    "        best_gini = 1.0 - sum((n / m) ** 2 for n in num_parent)\n",
    "        best_idx, best_thr = None, None\n",
    "        \n",
    "        # Loop through all features.#\n",
    "        for idx in range(self.n_features_):\n",
    "            thresholds, classes = zip(*sorted(zip(X[:, idx], y)))\n",
    "            \n",
    "            num_left = [0] * self.n_classes_\n",
    "            num_right = num_parent.copy()\n",
    "            \n",
    "            for i in range(1, m):\n",
    "                c = classes[i - 1]\n",
    "                num_left[c] += 1\n",
    "                gini_left = 1.0 - sum(\n",
    "                    (num_left[x] / i) ** 2 for x in range(self.n_classes_)\n",
    "                )\n",
    "                gini_right = 1.0 - sum(\n",
    "                    (num_right[x] / (m - i)) ** 2 for x in range(self.n_classes_)\n",
    "                )\n",
    "                \n",
    "                # Gini impurity calculated as the weighted average of the Gini\n",
    "                # of the children\n",
    "                gini  = (i * gini_left + (m - i) * gini_right) / m\n",
    "                \n",
    "                # The following condition is to make sure we don't try to\n",
    "                # split two points with identical values for that feature,\n",
    "                # as it is impossible (both have to end up on the same side\n",
    "                # of a split).\n",
    "                if thresholds[i] == thresholds[i - 1]:\n",
    "                    continue\n",
    "                    \n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_idx = idx\n",
    "                    best_thr = (thresholds[i] + thresholds[i - 1]) / 2 #midpoint\n",
    "\n",
    "            return best_idx, best_thr\n",
    "        \n",
    "class Node():\n",
    "    def __init__(\n",
    "        self,\n",
    "        gini,\n",
    "        num_samples,\n",
    "        num_samples_per_class,\n",
    "        predicted_class,\n",
    "    ):\n",
    "        self.gini = gini\n",
    "        self.num_samples = num_samples\n",
    "        self.num_samples_per_class = num_samples_per_class\n",
    "        self.predicted_class = predicted_class\n",
    "        self.left = None\n",
    "        self.right = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data.\n",
    "df = pd.read_csv('wifi_localization.txt', delimiter='\\t')\n",
    "data = df.to_numpy()\n",
    "X = data[:, :-1] # all columns but the last\n",
    "y = data[:, -1] - 1 # expected to be from 0 to n_classes - 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[348, 362, 334, 355]\n",
      "1\n",
      "[348, 361, 334, 355]\n",
      "1\n",
      "[348, 357, 334, 355]\n",
      "1\n",
      "[0, 4, 0, 0]\n",
      "1\n",
      "[0, 1, 0, 0]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Fit data.\n",
    "clf = DecisionTreeClassifier(max_depth=2)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Visualize.\n",
    "#clf.debug(\n",
    "#    features_names=[\"Wifi {}\".format(i) for i in range(1, 8)],\n",
    "#    target_names=[\"Room {}\".format(i) for i in range(1, 5)],\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([354, 277, 405, 507, 407, 409, 505, 503, 502, 129, 130, 261, 132,\n",
       "       493, 138, 139, 142, 252, 510, 424, 111, 280, 302,  86, 390, 395,\n",
       "       294, 523, 286, 402, 519, 100, 101, 102, 207, 404, 282, 281, 513,\n",
       "       109, 389, 486, 484, 441, 185, 219, 442, 459, 190, 444, 215, 194,\n",
       "       212, 456, 455, 199, 449, 201, 451, 204, 463, 430, 465, 467, 482,\n",
       "       156, 157, 239, 230, 166, 229, 169, 438, 171, 471, 173, 174, 226,\n",
       "       225, 439, 222, 221, 304, 517, 387, 343,  26, 575, 364,  29, 574,\n",
       "       340,  32, 344, 337, 332,  40,  42, 533, 372, 564, 327, 326,  34,\n",
       "       578, 345,  21,   1, 596, 595,   5, 350,   7, 361,   9, 348, 362,\n",
       "        12, 587, 586, 585, 584, 346,  18, 582, 581, 322,  50, 450,  58,\n",
       "        52, 318, 379, 314, 380, 549,  68, 546, 310, 544,  73, 541, 552,\n",
       "       384, 319,  60,  79,  53, 538, 377, 536, 278, 306, 316, 279, 208,\n",
       "       301, 359, 382, 289, 385, 447, 309, 292, 291, 214, 400, 443, 399,\n",
       "       223, 383, 376, 317, 412, 423, 266, 254, 419, 265, 269, 257, 258,\n",
       "       418, 260, 323, 264, 415, 375, 437, 247, 330, 231, 232, 436, 433,\n",
       "       237, 238, 329, 336, 334, 432, 408, 241, 242, 243, 367, 251, 299,\n",
       "       452,  91, 524,  94, 522,  98, 104, 205, 512, 112, 509, 117, 118,\n",
       "       119, 120, 506, 123, 504, 126, 127, 499, 133,  89, 528,  85, 531,\n",
       "       594,   6,  28,  31,  33,  35,  37, 569, 565,  46, 498, 559, 558,\n",
       "        51, 557, 551,  62,  64,  65, 548, 543, 534,  48, 496, 514, 140,\n",
       "       481, 477, 164, 475, 473, 472, 175, 176, 357, 468, 466, 462, 461,\n",
       "       460, 191, 457, 193, 195, 196, 158, 155, 470, 143, 152, 491, 151,\n",
       "       487, 490, 483, 369, 571, 371, 568, 515, 561, 374, 488, 414, 425,\n",
       "       426, 458, 489, 445, 416, 358, 454, 448, 592, 591, 588, 573, 583,\n",
       "       577, 576, 363, 421, 365, 366, 580, 469, 554, 553, 403, 511, 521,\n",
       "       401, 480, 478, 525, 434, 398, 526, 397, 396, 435, 394, 392, 527,\n",
       "       431, 411, 410, 550, 428, 485, 545, 556, 474, 537, 492, 406, 508,\n",
       "       529, 476, 539, 535,   0, 162, 184,  87,  84, 188, 197,  81,  80,\n",
       "       203,  78, 209,  76,  72, 228, 233,  63, 240, 244,  61,  59,  57,\n",
       "        56, 250, 253,  54,  47, 183, 262, 180, 177, 115, 128, 113, 131,\n",
       "       134, 110, 135, 108, 107, 136, 137, 144, 105, 146, 147, 149, 150,\n",
       "       153, 161, 355, 163,  97, 167,  96, 172, 179, 267, 245,  44,  27,\n",
       "       598, 300,  24, 305,  23, 311, 312,  19, 315,  16,  15, 298, 324,\n",
       "        14,  13, 331,  11, 338,   8, 342,   4,   3,   2, 352, 353, 325,\n",
       "        30, 303,  39, 270, 271,  43, 275,  41, 283, 284, 293, 122, 295,\n",
       "        82, 103,  77, 555, 516, 567, 566, 589, 590, 106, 518,  10,  36,\n",
       "       593,  49,  75, 560,  45, 597, 114, 540, 562,  55,  99, 520,  71,\n",
       "       532, 547,  83, 530, 563,  69, 572,  67, 579,  88,  90,  92,  22,\n",
       "        66,  93,  38,  20,  95, 570, 542,  17, 116,  70,  25,  74, 356,\n",
       "       124, 296, 290, 288, 287, 285, 276, 274, 273, 272, 268, 413, 263,\n",
       "       417, 259, 256, 420, 255, 422, 249, 297, 393, 391, 388, 351, 360,\n",
       "       349, 347, 341, 339, 335, 368, 333, 248, 370, 373, 321, 320, 378,\n",
       "       313, 381, 308, 307, 386, 328, 121, 427, 429, 182, 181, 178, 170,\n",
       "       168, 165, 479, 160, 159, 154, 148, 145, 141, 494, 495, 497, 500,\n",
       "       501, 125, 464, 186, 187, 189, 236, 235, 234, 227, 224, 440, 220,\n",
       "       218, 217, 246, 216, 446, 211, 210, 206, 202, 453, 200, 198, 192,\n",
       "       213, 599])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4]\n",
      "1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4e59de1094c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Fit data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-73c4f0607461>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grow_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-73c4f0607461>\u001b[0m in \u001b[0;36m_grow_tree\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# Split recursively until max_depth is reached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_best_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mindices_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-73c4f0607461>\u001b[0m in \u001b[0;36m_best_split\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;31m# as it is impossible (both have to end up on the same side\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0;31m# of a split).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "X = np.array([[4,5,6,3,4,5], [1,3,7,9,9,8]])\n",
    "y = np.array([1,1,0,1,1,0])\n",
    "\n",
    "# Fit data.\n",
    "clf = DecisionTreeClassifier(max_depth=2)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nf] *",
   "language": "python",
   "name": "conda-env-nf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
